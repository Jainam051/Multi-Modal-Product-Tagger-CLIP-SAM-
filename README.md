# ğŸ§  Multi-Modal Product Tagger (CLIP + SAM)

A powerful computer vision demo that combines [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything) by Meta and [CLIP](https://github.com/openai/CLIP) by OpenAI to **automatically segment and label objects in images** â€” all wrapped in a clean [Gradio](https://gradio.app) interface.

---

## ğŸ” Overview

This project takes an input image, segments all objects using **SAM**, and classifies each object using **CLIP** against ImageNet labels. Results are visualized with bounding boxes and labels directly on the image.

---

## ğŸ§° Features

- ğŸ” Object segmentation using SAM
- ğŸ§  Semantic classification using CLIP
- ğŸ¨ Real-time visualization of segments
- ğŸŒ Simple, shareable Gradio interface

