# ğŸ§  Multi-Modal Product Tagger (CLIP + SAM)

A powerful computer vision demo that combines [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything) by Meta and [CLIP](https://github.com/openai/CLIP) by OpenAI to **automatically segment and label objects in images** â€” all wrapped in a clean [Gradio](https://gradio.app) interface.

---

## ğŸ” Overview

This project takes an input image, segments all objects using **SAM**, and classifies each object using **CLIP** against ImageNet labels. Results are visualized with bounding boxes and labels directly on the image.

---

## ğŸš€ Demo

![demo](https://user-images.githubusercontent.com/demo-placeholder.gif)

Try it locally using the Gradio interface â€” no complex UI code needed.

---

## ğŸ§° Features

- ğŸ” Object segmentation using SAM
- ğŸ§  Semantic classification using CLIP
- ğŸ¨ Real-time visualization of segments
- ğŸŒ Simple, shareable Gradio interface

---

## ğŸ›  Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/multimodal-product-tagger.git
cd multimodal-product-tagger
# SAM-CLIP-Tagger
